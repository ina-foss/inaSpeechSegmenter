{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277fd4c7-edee-49ec-ab32-7826c8eb5b8b",
   "metadata": {},
   "source": [
    "# API tutorial for _VBx-Based_ Voice Femininity Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24967d1f-af52-4297-954e-2790fbb44214",
   "metadata": {
    "tags": []
   },
   "source": [
    "Perform feature extraction on the chosen file using the **VBx extraction pipeline** and add a **pre-trained gender detection model** on the output descriptors.  \n",
    "Notice that a voice activity detection (from _inaSpeechSegmenter.Segmenter_) is performed to compute the voice femininity score using gender predictions only on speech segments (cudNN version must be at least **8.6** if you want to use **tensorflow-2.12**).  \n",
    "  \n",
    "Make sure the recording has only one speaker to get a more accurate femininity score.\n",
    "\n",
    "> VFS = 1 means the voice gender prediction is \"female\"  \n",
    "> VFS = 0 means the voice gender prediction is \"male\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad980ae-b545-4ed8-966b-72c2a1bfe8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from inaSpeechSegmenter.vbx_segmenter import VoiceFemininityScoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce8116-89c2-46fd-83de-4a442b5d75e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select a media to analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331a19b-b699-4c0f-9082-c8ac63746824",
   "metadata": {
    "tags": []
   },
   "source": [
    "* duration < 680 ms  \n",
    "Voice femininity score = 0.000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c112d924-65a8-4435-87ac-ad8146f0300a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpath = \"../media/0021.mp3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5767fa9d-b342-4916-98ed-5d6636f104bd",
   "metadata": {},
   "source": [
    "* only music : an assertion error is raised indicating that no speech segment was found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78f269-126f-4ae5-a035-6053a264e86c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpath = \"../media/silence2sec.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3fc8e7-a318-4006-981e-b5042027b84a",
   "metadata": {},
   "source": [
    "* Example  \n",
    "Voice femininity score = 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40b25a-fd7a-4d49-81dc-9ecc68f7cc9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpath = \"../media/lamartine.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b875f8-0e17-4fbb-98c8-15ed65a165c9",
   "metadata": {},
   "source": [
    "### Create instance of _VBx-based_ Voice Femininity Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fec6ec-5964-4632-8f61-2f6f178f3cc1",
   "metadata": {},
   "source": [
    "_gd_model_criteria_ refers to the gender detection model used :  \n",
    ">\"**bgc**\" (default) : Multi layer perceptron trained on all data giving best BGC (i.e. interspeech2023 paper)  \n",
    "\"**vfp**\" : Multi layer perceptron trained on French CommonVoice giving best VFP (i.e. interspeech2023 paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518423cc-ab54-4fca-acdb-3347c9e7a391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v = VoiceFemininityScoring(backend='onnx', gd_model_criteria=\"vfp\")\n",
    "# v = VoiceFemininityScoring(backend='pytorch', gpu='0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4095553d-de59-4c20-a69d-dd98c5c3da14",
   "metadata": {},
   "source": [
    "#### Femininity score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e33670-d957-4f51-8936-1ae236c73d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vf_score, speech_detected, nb_retained_vectors = v(fpath)\n",
    "print(\"Detected speech duration : %.2fs\" % speech_detected)\n",
    "print(\"Voice femininity score : %.9f\" % vf_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
